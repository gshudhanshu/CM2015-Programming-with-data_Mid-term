{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c6450f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cryptocurrency data analysis and price prediction using ARIMA and Seasonal ARIMA model\n",
    "#### Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7eaec3",
   "metadata": {},
   "source": [
    "## 1. Aims, objective and background\n",
    "### 1.1 Introduction\n",
    "Cryptocurrencies are quickly challenging traditional currencies throughout the world. Digital currencies may be purchased in a variety of ways, making them accessible to everyone, and merchants adopting multiple cryptocurrencies could signal that money as we know it is about to undergo a huge transformation.\n",
    "\n",
    "Bitcoin was the first cryptocurrency launched in the year 2009 and since then the popularity and acceptibility of blockchain and cryptocurrencies has only grown upward direction. Due to its unique qualities of blockchain, such as security and transparency, cheaper cost and decentralisation, it is already being used to solve variety of real world problems as per Mallqui and Fernandes [5].\n",
    "\n",
    "This project was inspired by Chaudhari, A. (2020, June 11). Forecasting Cryptocurrency Prices using Machine Learning [3] and Chakrabarti, S. (2021, December 3). Cryptocurrency Price Prediction using ARIMA Model [4]. The authors used data science ARIMA, LSTM and Prophet models to predict the cryptocurrency prices.\n",
    "\n",
    "Currently the interest of investing in crypto is growning rapidly and there is less information about crypto relative to our traditional trading and this is a new platform for me researching. I love to research new things. So, I have decided to focus on next few months price prediction of top 4 cryptocurrencies.\n",
    "\n",
    "### 1.2 Aims and objectives\n",
    "For this project I would like to exlpore following things\n",
    "1. Analysing of history data of cryptocurrency.\n",
    "2. Using history data making visualizations (graphs)\n",
    "3. Looking for relationship of the graphs.\n",
    "4. Checking the instantaneous move of one coin (BTC) affect others.\n",
    "5. Using (Autoregressive integrated moving average) model and SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors) model for predicting next months prices.\n",
    "\n",
    "For this project my aims are\n",
    "1. Decide how much history data is required to use ARIMA and SARIMAX models.\n",
    "2. Decide which currencies will be best for my project.\n",
    "3. Collecting data via API/wesrapping and storing in better format so that I can do data cleaning.\n",
    "4. Clean the scraped or API history data suitable for data analysis\n",
    "5. Perform some data analysis to see if there are any trends in the data that may be helpful for future investigation.\n",
    "6. Calculate the accuracy of price predication.\n",
    "\n",
    "### 1.3 Data\n",
    "#### 1.3.1 Data requirement\n",
    "Right now there are more than 6000 crypto coins in the market. Taking consideration of time and resource. I have chosen to work on top 4 crypto coins to explore.\n",
    "I have decided to have equal number of history data for the coins and going to use data from one website because there are lot of exchanges and each exchange have slight differences.\n",
    "\n",
    "#### 1.3.2 Choice of history data website\n",
    "For the history data of coins, I am going to choose 1 website but first I made a list of good sources.\n",
    "\n",
    "1) www.investing.com        Scrapping / No API\n",
    "2) www.coinmarketcap.com    No Scrapping / API\n",
    "3) www.coingecko.com        No Scrapping / API\n",
    "4) www.coinpaprika.com      No Scrapping / API\n",
    "\n",
    "In this list only www.investing.com allowed data scrapping and other websites allowed on APIs only. API will be easy to collect data but then I will not able to use my new ability to scrap data. So, I am choosing www.investing.com [1].\n",
    "\n",
    "#### 1.3.3 Choice of the cryptocurrencies: methodology\n",
    "First point for choosing the currency will be the enough history data for analysis. Keeping the coin not related to each other. After it we need to check their rank [7], daily volume.\n",
    "\n",
    "Following are the selected coins:\n",
    "1) Bitcoin (BTC)\n",
    "2) Ethereum (ETH)\n",
    "3) Cardano (ADA)\n",
    "4) XRP (XRP)\n",
    "\n",
    "Originally I have choosen top 4 currencies but some don't have enough history for analysis and some are related to other currencies. They may have affected each other with the price change. So, I have skipped Binance Coin (BNB) and Solana (SOL).\n",
    "\n",
    "#### 1.3.4 Limitations and constraints of the data\n",
    "In this project I am going to use last 3 years of history data with per day value for analyase. This means I not going to use data from when the coin initiated in the market and this data not going to be per second/minute it will be per day.\n",
    "\n",
    "For analysing large data (per second or per minutes) will cause lot longer time for scrapping, cleaning and analysing the data. So, taking the account of limited time and resources I am going to use per day history values.\n",
    "\n",
    "Everyone know there are different event happened and it may have caused the price fluctuations, for example last few days everyone knows COVID caused lot of sudden fall in all the markets.\n",
    "\n",
    "### 1.4 Ethical considerations\n",
    "#### 1.4.1 Use of cryptocurrency history data\n",
    "www.investing.com allows to use their data but only ask to make sure to include full disclosure to Investing.com brand, logo, watermark and links if possible [1].\n",
    "\n",
    "#### 1.4.2 Onward use / reuseage and derived data\n",
    "Anyone wishing to use the source data must follow the term and conditions of www.investing.com and should take indiidual permission if necessary. The same term and condition apply to data producted from source data.\n",
    "\n",
    "Analysis and conclusions are my own.\n",
    "\n",
    "#### 1.4.3 Potential impacts of using cryptocurrency data for the proposes analyses\n",
    "Doing analysis of the source data may cause negative effect on the traders/cryptocurrencies. This may potential losses.\n",
    "1. Rather than making judgments on the currency will grow or fall. This project only focus on analysing objective.\n",
    "2. The project's findings will not claim to be a fully representative analysis. Limitations of data are outlined above. Limitations of techniques will be discussed further project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "48116822",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries and modules\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scipy\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "\n",
    "# Show all matplotlib graphs inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set all graphs to a seaborn style with a grey background grid which makes reading graphs easier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19487b37",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Web Scraping cryptocurrencies history data\n",
    "### 2.1 Defining scraping and extraction functions\n",
    "There going to be 3 years data for each coin.\n",
    "\n",
    "1) Bitcoin (BTC)\n",
    "2) Ethereum (ETH)\n",
    "3) Cardano (ADA)\n",
    "4) XRP (XRP)\n",
    "\n",
    "Before importing the data we need to make a function to iterate over the 4 urls.\n",
    "All the data of each coin going to be on 1 page so, data scraping will take few seconds. So, we don't need to worry about getting blocked or blacklisted.\n",
    "\n",
    "Below function will check if the website is accessible and returns the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "40269603",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "today = date.strftime(today, '%d/%m/%Y')\n",
    "\n",
    "# coinInfo dataframe includes required values to scrap data from Investing.com\n",
    "coinInfo = { 'bitcoin': {'name': 'bitcoin', 'symbol': 'BTC', 'curr_id': 1057391, 'smlID': 25609848},\n",
    "            'ethereum': {'name': 'ethereum', 'symbol': 'ETH', 'curr_id': 1061443, 'smlID': 25674078},\n",
    "            'cardano': {'name': 'cardano', 'symbol': 'ADA', 'curr_id': 1062537, 'smlID': 25948924},\n",
    "            'xrp': {'name': 'xrp', 'symbol': 'XRP', 'curr_id': 1057392, 'smlID': 25674343},}\n",
    "\n",
    "# getParsedWebPage function will scrap data from Investing.com and convert it to dataframe\n",
    "# Date format should in 'DD/MM/YYYY\"\n",
    "def getParsedWebPage(coinName, from_date, to_date):\n",
    "\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "\n",
    "    url = \"https://in.investing.com/instruments/HistoricalDataAjax\"\n",
    "    header = 'null'\n",
    "\n",
    "    payload = {'header': header,\n",
    "               'st_date': from_date, 'end_date': to_date,\n",
    "               'sort_col': 'date', 'action': 'historical_data',\n",
    "               'smlID': coinInfo[coinName], 'sort_ord': 'DESC', 'interval_sec': 'Daily', 'curr_id': coinInfo[coinName]['curr_id']}\n",
    "\n",
    "    res = requests.post(url, headers=headers, data=payload)\n",
    "\n",
    "    # Check that page is accessible for scraping\n",
    "    if res.status_code != 200:\n",
    "        soup = 'error'\n",
    "    else:\n",
    "        soup = BeautifulSoup(res.content, \"lxml\")\n",
    "        table = soup.find('table', id=\"curr_table\")\n",
    "        df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Adding Coin symbol and rearranging the columns\n",
    "    df['Symbol'] = coinInfo[coinName]['symbol']\n",
    "    df.rename(columns={'Vol.': 'Volume'}, inplace=True)\n",
    "    df = df[['Date', 'Symbol', 'Price', 'Open', 'High', 'Low', 'Volume']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe2944",
   "metadata": {},
   "source": [
    "### 2.1 Scraping the data\n",
    "We are going to scrap last 3 years data using function getParsedWebPage and appending all coins data in one dataframe. I am going to use from_date 365*3 = 1095 days before yesterday and to_date going to be yesterday because today's market may be not closed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc6410e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Date format should in 'DD/MM/YYYY\"\n",
    "# from_date = '21/12/2018'\n",
    "# to_date = '21/12/2021'\n",
    "\n",
    "today = date.today()\n",
    "\n",
    "yesterday = date.today() - timedelta (days = 1)\n",
    "\n",
    "to_date = yesterday\n",
    "from_date = yesterday - timedelta (days = 1095)\n",
    "\n",
    "# Modifying the date format\n",
    "from_date = date.strftime(from_date, '%d/%m/%Y')\n",
    "to_date = date.strftime(yesterday, '%d/%m/%Y')\n",
    "\n",
    "coinsHistoryDF = pd.DataFrame()\n",
    "\n",
    "# Scraping and appending the coin data in one DataFrame\n",
    "for coin in coinInfo:\n",
    "    coinData = getParsedWebPage(coin, from_date, to_date)\n",
    "    coinsHistoryDF = coinsHistoryDF.append(coinData, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688541a0",
   "metadata": {},
   "source": [
    "### 2.2 Check Scraped data\n",
    "We need to ensure that was scraped correctly and it does not go outside the required bounds.\n",
    "\n",
    "We're going to check the row count, ensure that it contains all the scraped coins and all values are not null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0db61542",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4384 entries, 0 to 4383\n",
      "Data columns (total 7 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Date    4384 non-null   object \n",
      " 1   Symbol  4384 non-null   object \n",
      " 2   Price   4384 non-null   float64\n",
      " 3   Open    4384 non-null   float64\n",
      " 4   High    4384 non-null   float64\n",
      " 5   Low     4384 non-null   float64\n",
      " 6   Volume  4384 non-null   object \n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 239.9+ KB\n",
      "None\n",
      "\n",
      "Unique coin symbols\n",
      "['BTC' 'ETH' 'ADA' 'XRP']\n"
     ]
    }
   ],
   "source": [
    "print(coinsHistoryDF.info())\n",
    "\n",
    "print(\"\\nUnique coin symbols\")\n",
    "print(coinsHistoryDF.Symbol.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e3f44",
   "metadata": {},
   "source": [
    "### 2.3 Import previously scraped data\n",
    "Because the history data of cryptocurrencies are being stored for long term and the content is not modified except in unavoidable circumstances, there is danger of altering the history data of the coins is very low but there is still change of modifications will occur on following\n",
    "\n",
    "1. Changes in Website content, design, AJAX calls\n",
    "2. History data may get removed\n",
    "3. Some reason if coin get banned and government may ask to remove all its content\n",
    "4. The website where we are scrapping it may go down due to some bugs\n",
    "\n",
    "If we keep our previously scraped data then such things will not happen and it will ensure of project consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b85cf839",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Saving previously scraped data in a csv file\n",
    "# coinsHistoryDF.to_csv('coinsHistory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "# Read previously scraped data\n",
    "coinsHistoryCSV = pd.read_csv('coinsHistory.csv', index_col=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "        Date Symbol Price  Open  High   Low Volume\ncount   4384   4384  4384  4384  4384  4384   4384\nunique     1      1     1     1     1     1      1\ntop     True   True  True  True  True  True   True\nfreq    4384   4384  4384  4384  4384  4384   4384",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Symbol</th>\n      <th>Price</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n      <td>4384</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previously scraped data should be the same as freshly scraped data\n",
    "(coinsHistoryCSV == coinsHistoryDF).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "79e4bbdf",
   "metadata": {},
   "source": [
    "## 7. References and Resources\n",
    "### 7.1 References\n",
    "[1]: Use our data. (n.d.). Investing Support. https://www.investing-support.com/hc/en-us/articles/360002357417\n",
    "[2]: FRANKENFIELD, J. A. K. E. (2021, December 20). Cryptocurrency. Investopedia. https://www.investopedia.com/terms/c/cryptocurrency.asp\n",
    "[3]: Chaudhari, A. (2020, June 11). Forecasting Cryptocurrency Prices using Machine Learning - NORMA@NCI Library. Norma.Ncirl.Ie. http://norma.ncirl.ie/4272/\n",
    "[4]: Chakrabarti, S. (2021, December 3). Cryptocurrency Price Prediction using ARIMA Model. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2021/12/cryptocurrency-price-prediction-using-arima-model/\n",
    "[5]: Mallqui, D., & Fernandes, R. (2019b, February 1). Predicting the direction, maximum, minimum and closing prices of daily Bitcoin exchange rate using machine learning techniques. ScienceDirect. https://www.sciencedirect.com/science/article/pii/S1568494618306707\n",
    "[6]: George, D. (2021, December 14). A Brief Introduction to ARIMA and SARIMAX Modeling in Python. Medium. https://medium.com/swlh/a-brief-introduction-to-arima-and-sarima-modeling-in-python-87a58d375def.\n",
    "\n",
    "[7]: CoinMarketCap. (n.d.-b). Todayâ€™s Top 100 Crypto Coins Prices And Data. Retrieved December 26, 2021, from https://coinmarketcap.com/coins/\n",
    "\n",
    "[8]: Rai, A. (2021, December 11). Python utility for data scrapping historical financial data- ML Data mining. Medium. https://medium.datadriveninvestor.com/python-utility-for-data-scrapping-historical-financial-data-ml-data-mining-5396dfe6f38c\n",
    "\n",
    "\n",
    "### 7.2 Resources used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb6847",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}