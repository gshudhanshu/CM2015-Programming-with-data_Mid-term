{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46c6450f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Cryptocurrency data analysis and price prediction using ARIMA and Seasonal ARIMA model\n",
    "#### Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7eaec3",
   "metadata": {},
   "source": [
    "## 1. Aims, objective and background\n",
    "### 1.1 Introduction\n",
    "Cryptocurrencies are quickly challenging traditional currencies throughout the world. Digital currencies may be purchased in a variety of ways, making them accessible to everyone, and merchants adopting multiple cryptocurrencies could signal that money as we know it is about to undergo a huge transformation.\n",
    "\n",
    "Bitcoin was the first cryptocurrency launched in the year 2009 and since then the popularity and acceptibility of blockchain and cryptocurrencies has only grown upward direction. Due to its unique qualities of blockchain, such as security and transparency, cheaper cost and decentralisation, it is already being used to solve variety of real world problems as per Mallqui and Fernandes [5].\n",
    "\n",
    "This project was inspired by Chaudhari, A. (2020, June 11). Forecasting Cryptocurrency Prices using Machine Learning [3] and Chakrabarti, S. (2021, December 3). Cryptocurrency Price Prediction using ARIMA Model [4]. The authors used data science ARIMA, LSTM and Prophet models to predict the cryptocurrency prices.\n",
    "\n",
    "Currently the interest of investing in crypto is growning rapidly and there is less information about crypto relative to our traditional trading and this is a new platform for me researching. I love to research new things. So, I have decided to focus on next few months price prediction of top 4 cryptocurrencies.\n",
    "\n",
    "### 1.2 Aims and objectives\n",
    "For this project I would like to exlpore following things\n",
    "1. Analysing of history data of cryptocurrency.\n",
    "2. Using history data making visualizations (graphs)\n",
    "3. Looking for relationship of the graphs.\n",
    "4. Checking the instantaneous move of one coin (BTC) affect others.\n",
    "5. Using (Autoregressive integrated moving average) model and SARIMAX (Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors) model for predicting next months prices.\n",
    "\n",
    "For this project my aims are\n",
    "1. Decide how much history data is required to use ARIMA and SARIMAX models.\n",
    "2. Decide which currencies will be best for my project.\n",
    "3. Collecting data via API/wesrapping and storing in better format so that I can do data cleaning.\n",
    "4. Clean the scraped or API history data suitable for data analysis\n",
    "5. Perform some data analysis to see if there are any trends in the data that may be helpful for future investigation.\n",
    "6. Calculate the accuracy of price predication.\n",
    "\n",
    "### 1.3 Data\n",
    "#### 1.3.1 Data requirement\n",
    "Right now there are more than 6000 crypto coins in the market. Taking consideration of time and resource. I have chosen to work on top 4 crypto coins to explore.\n",
    "I have decided to have equal number of history data for the coins and going to use data from one website because there are lot of exchanges and each exchange have slight differences.\n",
    "\n",
    "#### 1.3.2 Choice of history data website\n",
    "For the history data of coins, I am going to choose 1 website but first I made a list of good sources.\n",
    "\n",
    "1) www.investing.com        Scrapping / No API\n",
    "2) www.coinmarketcap.com    No Scrapping / API\n",
    "3) www.coingecko.com        No Scrapping / API\n",
    "4) www.coinpaprika.com      No Scrapping / API\n",
    "\n",
    "In this list only www.investing.com allowed data scrapping and other websites allowed on APIs only. API will be easy to collect data but then I will not able to use my new ability to scrap data. So, I am choosing www.investing.com [1].\n",
    "\n",
    "#### 1.3.3 Choice of the cryptocurrencies: methodology\n",
    "First point for choosing the currency will be the enough history data for analysis. Keeping the coin not related to each other. After it we need to check their rank [7], daily volume.\n",
    "\n",
    "Following are the selected coins:\n",
    "1) Bitcoin (BTC)\n",
    "2) Ethereum (ETH)\n",
    "3) Cardano (ADA)\n",
    "4) XRP (XRP)\n",
    "\n",
    "Originally I have choosen top 4 currencies but some don't have enough history for analysis and some are related to other currencies. They may have affected each other with the price change. So, I have skipped Binance Coin (BNB) and Solana (SOL).\n",
    "\n",
    "#### 1.3.4 Limitations and constraints of the data\n",
    "In this project I am going to use last 3 years of history data with per day value for analyase. This means I not going to use data from when the coin initiated in the market and this data not going to be per second/minute it will be per day.\n",
    "\n",
    "For analysing large data (per second or per minutes) will cause lot longer time for scrapping, cleaning and analysing the data. So, taking the account of limited time and resources I am going to use per day history values.\n",
    "\n",
    "Everyone know there are different event happened and it may have caused the price fluctuations, for example last few days everyone knows COVID caused lot of sudden fall in all the markets.\n",
    "\n",
    "### 1.4 Ethical considerations\n",
    "#### 1.4.1 Use of cryptocurrency history data\n",
    "www.investing.com allows to use their data but only ask to make sure to include full disclosure to Investing.com brand, logo, watermark and links if possible [1].\n",
    "\n",
    "#### 1.4.2 Onward use / reuseage and derived data\n",
    "Anyone wishing to use the source data must follow the term and conditions of www.investing.com and should take indiidual permission if necessary. The same term and condition apply to data producted from source data.\n",
    "\n",
    "Analysis and conclusions are my own.\n",
    "\n",
    "#### 1.4.3 Potential impacts of using cryptocurrency data for the proposes analyses\n",
    "Doing analysis of the source data may cause negative effect on the traders/cryptocurrencies. This may potential losses.\n",
    "1. Rather than making judgments on the currency will grow or fall. This project only focus on analysing objective.\n",
    "2. The project's findings will not claim to be a fully representative analysis. Limitations of data are outlined above. Limitations of techniques will be discussed further project.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48116822",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries and modules\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scipy\n",
    "import seaborn as sns\n",
    "\n",
    "import csv\n",
    "from datetime import date\n",
    "import datetime\n",
    "\n",
    "# Show all matplotlib graphs inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set all graphs to a seaborn style with a grey background grid which makes reading graphs easier\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19487b37",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2. Web Scraping cryptocurrencies history data\n",
    "### 2.1 Defining scraping and extraction functions\n",
    "There going to be 3 years data for each coin.\n",
    "\n",
    "1) Bitcoin (BTC)\n",
    "2) Ethereum (ETH)\n",
    "3) Cardano (ADA)\n",
    "4) XRP (XRP)\n",
    "\n",
    "Before importing the data we need to make a function to iterate over the 4 urls.\n",
    "All the data of each coin going to be on 1 page so, data scraping will take few seconds. So, we don't need to worry about getting blocked or blacklisted.\n",
    "\n",
    "Below function will check if the website is accessible and returns the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40269603",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "             Date Symbol    Price     Open     High      Low   Volume\n0    Dec 12, 2021    XRP  0.83990  0.83767  0.85633  0.80961  441.73M\n1    Dec 11, 2021    XRP  0.83722  0.79999  0.84336  0.78641  561.08M\n2    Dec 10, 2021    XRP  0.79916  0.85795  0.88198  0.79526  957.23M\n3    Dec 09, 2021    XRP  0.85809  0.86167  0.93300  0.83285    1.26B\n4    Dec 08, 2021    XRP  0.86148  0.81535  0.88302  0.80486  811.57M\n..            ...    ...      ...      ...      ...      ...      ...\n361  Dec 16, 2020    XRP  0.57120  0.46777  0.57337  0.43985    2.50B\n362  Dec 15, 2020    XRP  0.46783  0.49735  0.50706  0.46489    1.26B\n363  Dec 14, 2020    XRP  0.49747  0.51392  0.51810  0.48986  869.69M\n364  Dec 13, 2020    XRP  0.51416  0.50589  0.52755  0.48652    1.28B\n365  Dec 12, 2020    XRP  0.50589  0.54666  0.54739  0.48577    2.15B\n\n[366 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Symbol</th>\n      <th>Price</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Dec 12, 2021</td>\n      <td>XRP</td>\n      <td>0.83990</td>\n      <td>0.83767</td>\n      <td>0.85633</td>\n      <td>0.80961</td>\n      <td>441.73M</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Dec 11, 2021</td>\n      <td>XRP</td>\n      <td>0.83722</td>\n      <td>0.79999</td>\n      <td>0.84336</td>\n      <td>0.78641</td>\n      <td>561.08M</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Dec 10, 2021</td>\n      <td>XRP</td>\n      <td>0.79916</td>\n      <td>0.85795</td>\n      <td>0.88198</td>\n      <td>0.79526</td>\n      <td>957.23M</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Dec 09, 2021</td>\n      <td>XRP</td>\n      <td>0.85809</td>\n      <td>0.86167</td>\n      <td>0.93300</td>\n      <td>0.83285</td>\n      <td>1.26B</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dec 08, 2021</td>\n      <td>XRP</td>\n      <td>0.86148</td>\n      <td>0.81535</td>\n      <td>0.88302</td>\n      <td>0.80486</td>\n      <td>811.57M</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>Dec 16, 2020</td>\n      <td>XRP</td>\n      <td>0.57120</td>\n      <td>0.46777</td>\n      <td>0.57337</td>\n      <td>0.43985</td>\n      <td>2.50B</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>Dec 15, 2020</td>\n      <td>XRP</td>\n      <td>0.46783</td>\n      <td>0.49735</td>\n      <td>0.50706</td>\n      <td>0.46489</td>\n      <td>1.26B</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>Dec 14, 2020</td>\n      <td>XRP</td>\n      <td>0.49747</td>\n      <td>0.51392</td>\n      <td>0.51810</td>\n      <td>0.48986</td>\n      <td>869.69M</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>Dec 13, 2020</td>\n      <td>XRP</td>\n      <td>0.51416</td>\n      <td>0.50589</td>\n      <td>0.52755</td>\n      <td>0.48652</td>\n      <td>1.28B</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>Dec 12, 2020</td>\n      <td>XRP</td>\n      <td>0.50589</td>\n      <td>0.54666</td>\n      <td>0.54739</td>\n      <td>0.48577</td>\n      <td>2.15B</td>\n    </tr>\n  </tbody>\n</table>\n<p>366 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = date.today()\n",
    "today = date.strftime(today, '%d/%m/%Y')\n",
    "\n",
    "# coinInfo dataframe includes required values to scrap data from Investing.com\n",
    "coinInfo = { 'bitcoin': {'name': 'bitcoin', 'symbol': 'BTC', 'curr_id': 1057391, 'smlID': 25609848},\n",
    "            'ethereum': {'name': 'ethereum', 'symbol': 'ETH', 'curr_id': 1061443, 'smlID': 25674078},\n",
    "            'cardano': {'name': 'cardano', 'symbol': 'ADA', 'curr_id': 1062537, 'smlID': 25948924},\n",
    "            'xrp': {'name': 'xrp', 'symbol': 'XRP', 'curr_id': 1057392, 'smlID': 25674343},}\n",
    "\n",
    "# getParsedWebPage function will scrap data from Investing.com and convert it to dataframe\n",
    "# Date format should in 'DD/MM/YYYY\"\n",
    "def getParsedWebPage(coinName, from_date, to_date):\n",
    "\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36\", \"X-Requested-With\": \"XMLHttpRequest\"}\n",
    "\n",
    "    url = \"https://in.investing.com/instruments/HistoricalDataAjax\"\n",
    "    header = 'null'\n",
    "\n",
    "    payload = {'header': header,\n",
    "               'st_date': from_date, 'end_date': to_date,\n",
    "               'sort_col': 'date', 'action': 'historical_data',\n",
    "               'smlID': coinInfo[coinName], 'sort_ord': 'DESC', 'interval_sec': 'Daily', 'curr_id': coinInfo[coinName]['curr_id']}\n",
    "\n",
    "    res = requests.post(url, headers=headers, data=payload)\n",
    "\n",
    "    # Check that page is accessible for scraping\n",
    "    if res.status_code != 200:\n",
    "        soup = 'error'\n",
    "    else:\n",
    "        soup = BeautifulSoup(res.content, \"lxml\")\n",
    "        table = soup.find('table', id=\"curr_table\")\n",
    "        df = pd.read_html(str(table))[0]\n",
    "\n",
    "    # Adding Coin symbol and rearranging the columns\n",
    "    df['Symbol'] = 'XRP'\n",
    "    df.rename(columns={'Vol.': 'Volume'}, inplace=True)\n",
    "    df = df[['Date', 'Symbol', 'Price', 'Open', 'High', 'Low', 'Volume']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e4bbdf",
   "metadata": {},
   "source": [
    "## 7. References and Resources\n",
    "### 7.1 References\n",
    "[1]: Use our data. (n.d.). Investing Support. https://www.investing-support.com/hc/en-us/articles/360002357417\n",
    "[2]: FRANKENFIELD, J. A. K. E. (2021, December 20). Cryptocurrency. Investopedia. https://www.investopedia.com/terms/c/cryptocurrency.asp\n",
    "[3]: Chaudhari, A. (2020, June 11). Forecasting Cryptocurrency Prices using Machine Learning - NORMA@NCI Library. Norma.Ncirl.Ie. http://norma.ncirl.ie/4272/\n",
    "[4]: Chakrabarti, S. (2021, December 3). Cryptocurrency Price Prediction using ARIMA Model. Analytics Vidhya. https://www.analyticsvidhya.com/blog/2021/12/cryptocurrency-price-prediction-using-arima-model/\n",
    "[5]: Mallqui, D., & Fernandes, R. (2019b, February 1). Predicting the direction, maximum, minimum and closing prices of daily Bitcoin exchange rate using machine learning techniques. ScienceDirect. https://www.sciencedirect.com/science/article/pii/S1568494618306707\n",
    "[6]: George, D. (2021, December 14). A Brief Introduction to ARIMA and SARIMAX Modeling in Python. Medium. https://medium.com/swlh/a-brief-introduction-to-arima-and-sarima-modeling-in-python-87a58d375def.\n",
    "\n",
    "[7]: CoinMarketCap. (n.d.-b). Today’s Top 100 Crypto Coins Prices And Data. Retrieved December 26, 2021, from https://coinmarketcap.com/coins/\n",
    "\n",
    "[8]: Rai, A. (2021, December 11). Python utility for data scrapping historical financial data- ML Data mining. Medium. https://medium.datadriveninvestor.com/python-utility-for-data-scrapping-historical-financial-data-ml-data-mining-5396dfe6f38c\n",
    "\n",
    "\n",
    "### 7.2 Resources used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb6847",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}